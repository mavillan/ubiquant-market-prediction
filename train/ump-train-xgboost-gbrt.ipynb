{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8da1d83",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 2.339034,
     "end_time": "2022-02-02T14:40:37.761161",
     "exception": false,
     "start_time": "2022-02-02T14:40:35.422127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import xgboost as xgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c327ca6d-6879-41f3-9e56-130745308691",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_env = \"local\"\n",
    "\n",
    "if current_env == \"local\":\n",
    "    data_path = \"../ump-dataset\"\n",
    "\n",
    "elif current_env == \"kaggle\":\n",
    "    data_path = \"../input/ump-dataset\"\n",
    "    \n",
    "elif current_env == \"colab\":\n",
    "    pass\n",
    "\n",
    "print(\"data_path:\", data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51f581d",
   "metadata": {
    "papermill": {
     "duration": 0.01652,
     "end_time": "2022-02-02T14:40:37.794915",
     "exception": false,
     "start_time": "2022-02-02T14:40:37.778395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "## loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bec8f6",
   "metadata": {
    "papermill": {
     "duration": 40.967849,
     "end_time": "2022-02-02T14:41:18.779238",
     "exception": false,
     "start_time": "2022-02-02T14:40:37.811389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = [f\"f_{i}\" for i in range(300)]\n",
    "\n",
    "features = pd.read_parquet(f\"{data_path}/train.parquet\", columns=features)\n",
    "target = pd.read_parquet(f\"{data_path}/train.parquet\", columns=[\"target\",])\n",
    "time = pd.read_parquet(f\"{data_path}/train.parquet\", columns=[\"time_id\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5dc8bb",
   "metadata": {
    "papermill": {
     "duration": 0.073857,
     "end_time": "2022-02-02T14:41:18.879082",
     "exception": false,
     "start_time": "2022-02-02T14:41:18.805225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_ids = np.sort(time.time_id.unique())\n",
    "len(time_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da735ba",
   "metadata": {
    "papermill": {
     "duration": 0.030696,
     "end_time": "2022-02-02T14:41:18.928562",
     "exception": false,
     "start_time": "2022-02-02T14:41:18.897866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_time_steps = len(time_ids)\n",
    "print(\"time steps:\", n_time_steps)\n",
    "\n",
    "valid_prop = 0.1\n",
    "valid_size = int(0.1 * n_time_steps)\n",
    "print(\"valid size:\", valid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320f66b2",
   "metadata": {
    "papermill": {
     "duration": 0.445881,
     "end_time": "2022-02-02T14:41:19.395000",
     "exception": false,
     "start_time": "2022-02-02T14:41:18.949119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train-valid splits\n",
    "n_splits = 3\n",
    "end_idx = n_time_steps \n",
    "\n",
    "splits = list()\n",
    "\n",
    "for start_idx in np.arange(1211, 0, -valid_size)[1:n_splits+1]:\n",
    "    valid_time_ids = time_ids[start_idx:end_idx]\n",
    "    train_time_end = time_ids[start_idx]-1\n",
    "    end_idx = start_idx\n",
    "    \n",
    "    train_idx = time.query(\"time_id <= @train_time_end\").index\n",
    "    valid_idx = time.query(\"time_id in @valid_time_ids\").index\n",
    "    splits.append((train_idx,valid_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa557a5",
   "metadata": {
    "papermill": {
     "duration": 0.211454,
     "end_time": "2022-02-02T14:41:19.628355",
     "exception": false,
     "start_time": "2022-02-02T14:41:19.416901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d82923a",
   "metadata": {
    "papermill": {
     "duration": 0.020321,
     "end_time": "2022-02-02T14:41:19.668154",
     "exception": false,
     "start_time": "2022-02-02T14:41:19.647833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "## model training: finding number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2abdebe",
   "metadata": {
    "papermill": {
     "duration": 0.028505,
     "end_time": "2022-02-02T14:41:19.715920",
     "exception": false,
     "start_time": "2022-02-02T14:41:19.687415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pearsonr(preds: np.array, dset: xgb.DMatrix):\n",
    "    \"\"\"\n",
    "    Helper function to compute Pearson correlation \n",
    "    on validation dataset for LightGBM as tracking metric.\n",
    "    Args:\n",
    "        preds: 1d-array with the model predictions\n",
    "        dset: DMatrix dataset with the labels\n",
    "    Returs:\n",
    "        Tuple with the corresponding output\n",
    "    \"\"\"\n",
    "    labels = dset.get_label()\n",
    "    return 'pearsonr', stats.pearsonr(preds, labels)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047a8ea0",
   "metadata": {
    "papermill": {
     "duration": 0.028841,
     "end_time": "2022-02-02T14:41:19.764709",
     "exception": false,
     "start_time": "2022-02-02T14:41:19.735868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"tree_method\":\"hist\",\n",
    "    \"grow_policy\":\"depthwise\",\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'eta': 0.05,\n",
    "    'seed': 19,\n",
    "    'verbosity': 1,\n",
    "    'max_depth':7,\n",
    "    'max_bin':256,\n",
    "    'colsample_bytree':0.3,\n",
    "    'subsample':0.9,\n",
    "    'reg_alpha':1,\n",
    "    'reg_lambda':0.1,\n",
    "    'min_child_weight':1000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53343033",
   "metadata": {
    "papermill": {
     "duration": 1845.873018,
     "end_time": "2022-02-02T15:12:05.657875",
     "exception": false,
     "start_time": "2022-02-02T14:41:19.784857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pretrain = True\n",
    "metrics = {\"corr_mean\":list(), \"corr_std\":list(), \"error_mean\":list(), \"error_std\":list(),}\n",
    "\n",
    "if pretrain:\n",
    "    \n",
    "    models = list()\n",
    "\n",
    "    for train_idx,valid_idx in splits:\n",
    "        \n",
    "        # input datasets for xgb\n",
    "        train_dset = xgb.DMatrix(\n",
    "            data=features.loc[train_idx,:],\n",
    "            label=target.loc[train_idx,\"target\"].values,\n",
    "        )\n",
    "        valid_dset = xgb.DMatrix(\n",
    "            data=features.loc[valid_idx,:],\n",
    "            label=target.loc[valid_idx,\"target\"].values,\n",
    "        )\n",
    "        \n",
    "        model = xgb.train(\n",
    "            params=model_params,\n",
    "            num_boost_round=3000,\n",
    "            dtrain=train_dset,\n",
    "            evals=[(valid_dset,\"valid\"),],\n",
    "            feval=pearsonr,\n",
    "            maximize=True,\n",
    "            early_stopping_rounds=50,\n",
    "            verbose_eval=20,\n",
    "        )\n",
    "        models.append(model)\n",
    "\n",
    "        xgb.plot_importance(model, importance_type=\"weight\", max_num_features=30)\n",
    "        xgb.plot_importance(model, importance_type=\"gain\", max_num_features=30)\n",
    "        plt.show()\n",
    "        \n",
    "        # residual analysis on oof predictions\n",
    "        oof = target.loc[valid_idx,:].copy()\n",
    "        oof[\"time_id\"] = time.loc[valid_idx,\"time_id\"]\n",
    "        oof[\"pred\"] = model.predict(valid_dset)\n",
    "        oof[\"target_abs\"] = oof.eval(\"abs(target)\")\n",
    "        oof[\"dev\"] = oof.eval(\"abs(target-pred)\")\n",
    "\n",
    "        corrs = oof.groupby(\"time_id\").apply(lambda x: stats.pearsonr(x.target, x.pred)[0])\n",
    "        corr_mean = corrs.mean()\n",
    "        corr_std = corrs.std()\n",
    "        error = oof.groupby(\"time_id\").apply(lambda x: np.sqrt(np.mean((x.target-x.pred)**2)))\n",
    "        error_mean = error.mean()\n",
    "        error_std = error.std()\n",
    "        \n",
    "        metrics[\"corr_mean\"].append(corr_mean)\n",
    "        metrics[\"corr_std\"].append(corr_std)\n",
    "        metrics[\"error_mean\"].append(error_mean)\n",
    "        metrics[\"error_std\"].append(error_std)\n",
    "\n",
    "        plt.figure(figsize=(18,8))\n",
    "        plt.subplot(1,2,1)\n",
    "        corrs.plot()\n",
    "        plt.axhline(\n",
    "            y=corr_mean, \n",
    "            color='r', \n",
    "            linestyle='-', \n",
    "            label=f\"corr_mean={corr_mean:.5f} & corr_std={corr_std:.5f}\"\n",
    "        )\n",
    "        plt.grid()\n",
    "        plt.ylabel(\"corr\")\n",
    "        plt.legend(loc=\"best\")\n",
    "        ##\n",
    "        plt.subplot(1,2,2)\n",
    "        error.plot()\n",
    "        plt.axhline(\n",
    "            y=error_mean, \n",
    "            color='r', \n",
    "            linestyle='-', \n",
    "            label=f\"rmse_mean={error_mean:.5f} & error_std={error_std:.5f}\"\n",
    "        )\n",
    "        plt.grid()\n",
    "        plt.ylabel(\"rmse\")\n",
    "        plt.legend(loc=\"best\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(22,8))\n",
    "        ##\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.plot(oof.sort_values(\"target_abs\").target_abs.values, oof.sort_values(\"target_abs\").dev.values)\n",
    "        plt.xlabel(\"target_abs\")\n",
    "        plt.ylabel(\"deviance (abs)\")\n",
    "        plt.grid()\n",
    "        ##\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.plot(oof.sort_values(\"target\").target.values, oof.sort_values(\"target\").dev.values)\n",
    "        plt.xlabel(\"target\")\n",
    "        plt.ylabel(\"deviance (abs)\")\n",
    "        plt.grid()\n",
    "        ##\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.plot(oof.sort_values(\"target\").target.values, oof.sort_values(\"target\").pred.values)\n",
    "        plt.xlabel(\"target\")\n",
    "        plt.ylabel(\"pred\")\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        \n",
    "        ## correlation vs target value\n",
    "        oof[\"target_pct\"] = ((100-1e-10)*oof.target.rank(pct=True)).astype(int)\n",
    "        #oof[\"target_pct\"] = 5*(oof.target_pct/5).astype(int)\n",
    "\n",
    "        bucket_corr = (\n",
    "            oof\n",
    "            .groupby(\"target_pct\")\n",
    "            .apply(lambda x: stats.pearsonr(x.target, x.pred)[0])\n",
    "            .reset_index()\n",
    "            .rename({0:\"corr\"}, axis=1)\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(12,5))\n",
    "        plt.plot(bucket_corr[\"target_pct\"], bucket_corr[\"corr\"])\n",
    "        plt.xlabel(\"target_quantile\")\n",
    "        plt.ylabel(\"correlation\")\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "           \n",
    "    n_iterations = int(np.mean([m.best_iteration for m in models]))\n",
    "    \n",
    "else:\n",
    "    # default value\n",
    "    n_iterations = 600\n",
    "    \n",
    "\n",
    "print(\"n_iterations:\", n_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da366919",
   "metadata": {
    "papermill": {
     "duration": 0.085392,
     "end_time": "2022-02-02T15:12:05.820074",
     "exception": false,
     "start_time": "2022-02-02T15:12:05.734682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6916fdc5",
   "metadata": {
    "papermill": {
     "duration": 0.08627,
     "end_time": "2022-02-02T15:12:05.984612",
     "exception": false,
     "start_time": "2022-02-02T15:12:05.898342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mean corr on validation\n",
    "np.mean(metrics[\"corr_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140f47d5",
   "metadata": {
    "papermill": {
     "duration": 0.08693,
     "end_time": "2022-02-02T15:12:06.149238",
     "exception": false,
     "start_time": "2022-02-02T15:12:06.062308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mean rmse on validation\n",
    "np.mean(metrics[\"error_mean\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feba941",
   "metadata": {
    "papermill": {
     "duration": 0.077439,
     "end_time": "2022-02-02T15:12:06.304432",
     "exception": false,
     "start_time": "2022-02-02T15:12:06.226993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "## model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d541af",
   "metadata": {
    "papermill": {
     "duration": 3841.204544,
     "end_time": "2022-02-02T16:16:07.586971",
     "exception": false,
     "start_time": "2022-02-02T15:12:06.382427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [2,7,11,19,23]\n",
    "models = list()\n",
    "\n",
    "train_dset = xgb.DMatrix(\n",
    "    data=features,\n",
    "    label=target.target.values,\n",
    ")\n",
    "\n",
    "for seed in seeds:\n",
    "    _model_params = dict(model_params)\n",
    "    _model_params[\"seed\"] = seed\n",
    "    \n",
    "    \n",
    "    model = xgb.train(\n",
    "        params=_model_params,\n",
    "        num_boost_round=n_iterations,\n",
    "        dtrain=train_dset,\n",
    "        evals=[(train_dset,\"train\"),],\n",
    "        feval=pearsonr,\n",
    "        maximize=True,\n",
    "        verbose_eval=50,\n",
    "    )\n",
    "    models.append(model)\n",
    "\n",
    "    xgb.plot_importance(model, importance_type=\"weight\", max_num_features=30)\n",
    "    xgb.plot_importance(model, importance_type=\"gain\", max_num_features=30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2d5d15",
   "metadata": {
    "papermill": {
     "duration": 0.412971,
     "end_time": "2022-02-02T16:16:08.142537",
     "exception": false,
     "start_time": "2022-02-02T16:16:07.729566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for seed,model in zip(seeds,models): \n",
    "    model.save_model(f\"../ump-artifacts/xgboost-gbrt/xgb-seed{seed}.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f152bfa8",
   "metadata": {
    "papermill": {
     "duration": 0.138355,
     "end_time": "2022-02-02T16:16:08.419790",
     "exception": false,
     "start_time": "2022-02-02T16:16:08.281435",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "## inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e748b9d-3975-4647-b7bd-8c79b24d87ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if current_env == \"kaggle\":\n",
    "\n",
    "    import ubiquant\n",
    "    env = ubiquant.make_env()  \n",
    "    iter_test = env.iter_test()\n",
    "    \n",
    "    features = [f\"f_{i}\" for i in range(300)]\n",
    "    for (test_df, sample_prediction_df) in iter_test:  \n",
    "        preds = [model.predict(test_df[features]) for model in models]\n",
    "        sample_prediction_df['target'] = np.mean(preds, axis=0)\n",
    "        env.predict(sample_prediction_df) \n",
    "        display(sample_prediction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5300a7c",
   "metadata": {
    "papermill": {
     "duration": 0.14587,
     "end_time": "2022-02-02T16:16:09.886636",
     "exception": false,
     "start_time": "2022-02-02T16:16:09.740766",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5747.468077,
   "end_time": "2022-02-02T16:16:11.364136",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-02T14:40:23.896059",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
